name: Agent Build Refactored

on:
  push:
    branches:
      - master
      - build-python-dockerfile
  pull_request:
    branches:
      - master

  workflow_dispatch:

  schedule:
    - cron: '0 4 * * *'

permissions:
  contents: read

jobs:
  pre_job:
    name: Skip Duplicate Jobs Pre Job
    runs-on: ubuntu-latest
    permissions:
      actions: write  # Needed for skip-duplicate-jobs job
      contents: read
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
      python_version: ${{ steps.define_constants.outputs.python_version }}
      cache_version: ${{ steps.define_constants.outputs.cache_version }}
      aws_region: ${{ steps.define_constants.outputs.aws_region }}
      aws_security_group: ${{ steps.define_constants.outputs.aws_security_group }}
      aws_prefix_list_id: ${{ steps.define_constants.outputs.aws_prefix_list_id }}
      aws_objects_name_prefix: ${{ steps.define_constants.outputs.aws_objects_name_prefix }}
      CT_AWS_DEV_EC2_PRIVATE_KEY_NAME: ${{ steps.define_constants.outputs.CT_AWS_DEV_EC2_PRIVATE_KEY_NAME }}
    steps:
      - id: skip_check
        uses: fkirc/skip-duplicate-actions@12aca0a884f6137d619d6a8a09fcc3406ced5281 # v4.0.0
        with:
          cancel_others: 'true'
          github_token: ${{ github.token }}

      - id: define_constants
        run: |
          echo "python_version=3.8" >> "${GITHUB_OUTPUT}"
          echo "cache_version=4" >> "${GITHUB_OUTPUT}"
          echo "aws_region=us-east-1" >> "${GITHUB_OUTPUT}"
          echo "aws_security_group=github-actions-remote-access" >> "${GITHUB_OUTPUT}"
          echo "aws_prefix_list_id=pl-04a16228a97704d23" >> "${GITHUB_OUTPUT}"
          echo "aws_objects_name_prefix=${{ github.run_id }}-${{ github.run_number }}-${{ github.run_attempt }}" >> "${GITHUB_OUTPUT}"
          echo "CT_AWS_DEV_EC2_PRIVATE_KEY_NAME=CT_SCALYR_AGENT_GHA" >> "${GITHUB_OUTPUT}"

  verify_all_cacheable_dependencies:
    name: "Verify all cacheable dependencies"
    needs:
      - pre_job
    runs-on: ubuntu-22.04
    outputs:
      cache_miss: ${{ steps.verify.outputs.cache_miss }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: install python and requirements
        uses: ./.github/actions/install_python_and_requirements
        with:
          python_version: ${{ inputs.python_version }}

      - name: Expose GitHub Runtime To Be Able to Use GHA Cache By Docker.
        uses: crazy-max/ghaction-github-runtime@715c25b40ccc0df9b62bfa8be3ccc57d09dbc4b1

      - name: Verify
        id: verify
        env:
          BUILDER_MODULES: tests.end_to_end_tests
          USE_GHA_CACHE: "1"
          CACHE_VERSION: ${{ needs.pre_job.outputs.cache_version }}
        run: |
          OUTPUT="$(python3 agent_build_refactored/scripts/cicd/verify_all_dependencies_caches.py)"
          
          if [ "${OUTPUT}" == "cache_miss" ]; then
            echo "cache_miss=true" >> "$GITHUB_OUTPUT"
            echo "Expected output of the build command has to be 'cache_hit' but it is '${OUTPUT}'"
          fi

  build_cacheable_dependencies:
    needs:
      - pre_job
      - verify_all_cacheable_dependencies
    if: needs.verify_all_cacheable_dependencies.outputs.cache_miss == 'true'
    uses: ./.github/workflows/reusable-build-cacheable-dependencies.yml
    with:
      is_cache_miss: ${{ needs.verify_all_cacheable_dependencies.outputs.cache_miss }}
      python_version: ${{ needs.pre_job.outputs.python_version }}
      cache_version: ${{ needs.pre_job.outputs.cache_version }}
      aws_region: ${{ needs.pre_job.outputs.aws_region }}
      aws_security_group: ${{ needs.pre_job.outputs.aws_security_group }}
      aws_prefix_list_id: ${{ needs.pre_job.outputs.aws_prefix_list_id }}
      aws_objects_name_prefix: ${{ needs.pre_job.outputs.aws_objects_name_prefix }}
      CT_AWS_DEV_EC2_PRIVATE_KEY_NAME: ${{ needs.pre_job.outputs.CT_AWS_DEV_EC2_PRIVATE_KEY_NAME }}
    secrets:
      CT_AWS_DEV_EC2_PRIVATE_KEY: ${{ secrets.CT_AWS_DEV_EC2_PRIVATE_KEY }}
      CT_AWS_DEV_EC2_ACCESS_KEY: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
      CT_AWS_DEV_EC2_SECRET_KEY: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE }}
      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ }}


#  build_cached_linux_packages:
#    name: "Build cached Linux packages"
#    needs:
#      - pre_job
#    uses: ./.github/workflows/reusable-agent-build-linux-packages-new.yml
#    with:
#      python_version: ${{ needs.pre_job.outputs.python_version }}
#      cache_version: ${{ needs.pre_job.outputs.cache_version }}
#      aws_region: ${{ needs.pre_job.outputs.aws_region }}
#      aws_security_group: ${{ needs.pre_job.outputs.aws_security_group }}
#      aws_prefix_list_id: ${{ needs.pre_job.outputs.aws_prefix_list_id }}
#      aws_objects_name_prefix: ${{ needs.pre_job.outputs.aws_objects_name_prefix }}
#      CT_AWS_DEV_EC2_PRIVATE_KEY_NAME: ${{ needs.pre_job.outputs.CT_AWS_DEV_EC2_PRIVATE_KEY_NAME }}
#    secrets:
#      CT_AWS_DEV_EC2_PRIVATE_KEY: ${{ secrets.CT_AWS_DEV_EC2_PRIVATE_KEY }}
#      CT_AWS_DEV_EC2_ACCESS_KEY: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
#      CT_AWS_DEV_EC2_SECRET_KEY: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
#      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE }}
#      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ }}


  continue:
    name: "Continue"
    runs-on: ubuntu-22.04
    needs:
      - pre_job
      - verify_all_cacheable_dependencies
    if: needs.build_cacheable_dependencies.result == 'skipped' || success()
    steps:
      - run: echo "continue"



  build_linux_packages:
    name: "Build Linux packages"
    needs:
      - pre_job
      - verify_all_cacheable_dependencies
    uses: ./.github/workflows/reusable-agent-build-linux-packages-new.yml
    with:
      python_version: ${{ needs.pre_job.outputs.python_version }}
      cache_version: ${{ needs.pre_job.outputs.cache_version }}
      aws_region: ${{ needs.pre_job.outputs.aws_region }}
      aws_security_group: ${{ needs.pre_job.outputs.aws_security_group }}
      aws_prefix_list_id: ${{ needs.pre_job.outputs.aws_prefix_list_id }}
      aws_objects_name_prefix: ${{ needs.pre_job.outputs.aws_objects_name_prefix }}
      CT_AWS_DEV_EC2_PRIVATE_KEY_NAME: ${{ needs.pre_job.outputs.CT_AWS_DEV_EC2_PRIVATE_KEY_NAME }}
    secrets:
      CT_AWS_DEV_EC2_PRIVATE_KEY: ${{ secrets.CT_AWS_DEV_EC2_PRIVATE_KEY }}
      CT_AWS_DEV_EC2_ACCESS_KEY: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
      CT_AWS_DEV_EC2_SECRET_KEY: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE }}
      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ }}


#  build-linux-packages:
#    name: "Build Linux packages"
#    uses: ./.github/workflows/reusable-agent-build-linux-packages-new.yml
#    secrets:
#      CT_AWS_DEV_EC2_PRIVATE_KEY: ${{ secrets.CT_AWS_DEV_EC2_PRIVATE_KEY }}
#      CT_AWS_DEV_EC2_ACCESS_KEY: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
#      CT_AWS_DEV_EC2_SECRET_KEY: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
#      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE }}
#      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ: ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ }}
#
#  build-windows-package:
#    name: "Build Windows package"
#    uses: ./.github/workflows/reusable-agent-build-windows.yml
#    secrets:
#      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
#
#  build_tarball:
#    runs-on: ubuntu-20.04
#
#    steps:
#      - name: Checkout repository
#        uses: actions/checkout@v3
#
#      - name: Install python
#        uses: actions/setup-python@v4
#        with:
#          python-version: "3.8.13"
#
#      - name: Build tarball
#        run: |
#          mkdir -p build/tarball/noarch
#          pushd build/tarball/noarch
#          python3 ../../../build_package.py tarball
#          popd
#
#      - name: Save tarball as artifact
#        uses: actions/upload-artifact@v3
#        with:
#          name: tarball-noarch
#          path: build
#          retention-days: 1
#
#      - name: Notify Slack on Failure
#        if: ${{ failure() && github.ref_name == 'master' }}
#        uses: act10ns/slack@ed1309ab9862e57e9e583e51c7889486b9a00b0f # v2.0.0
#        env:
#          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
#        with:
#          status: ${{ job.status }}
#          steps: ${{ toJson(steps) }}
#          channel: '#eng-dataset-cloud-tech'
#
#
#  # Aggregate all agent build artifacts that we build by this workflow and put in a single artifact,
#  # so it's just need to download only one artifact, for example during a release process.
#  prepare-artifacts:
#    runs-on: ubuntu-20.04
#    needs:
#      - build-linux-packages
#      - build-windows-package
#      - build_tarball
#
#    steps:
#      - name: Checkout repository
#        uses: actions/checkout@v3
#
#      - name: Download artifacts
#        uses: actions/download-artifact@v3
#        with:
#          path: /tmp/all_artifacts
#
#
#      - name: Prepare artifacts
#        run: |
#          mkdir -p /tmp/result_artifacts
#          cp -a /tmp/all_artifacts/linux-packages-*/. /tmp/result_artifacts
#          cp -a /tmp/all_artifacts/tarball-noarch/. /tmp/result_artifacts
#          cp -a /tmp/all_artifacts/windows-msi/. /tmp/result_artifacts
#
#
#
#      - name: Save result artifact
#        uses: actions/upload-artifact@v3
#        with:
#          name: result-artifacts
#          path: /tmp/result_artifacts
#          retention-days: 1
