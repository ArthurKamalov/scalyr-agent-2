name: Agent Linux Packages Build Refactored

on:
  workflow_call:
    inputs:
      aws_private_key_name:
        type: string
      aws_region:
        type: string
      aws_security_group:
        type: string
      aws_prefix_list_id:
        type: string
      aws_objects_name_prefix:
        type: string

    secrets:
      CT_AWS_DEV_EC2_PRIVATE_KEY:
        required: true
      CT_AWS_DEV_EC2_ACCESS_KEY:
        required: true
      CT_AWS_DEV_EC2_SECRET_KEY:
        required: true
      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE:
        required: true
      CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ:
        required: true

env:
  DOCKER_BUILDKIT: 1
  # Set this variable to tell the agent build code that it runs in CI/CD and it needs to use caching.
  AGENT_BUILD_IN_CICD: "1"

# This job skips another workflows with identical content and also generates strategy matrices for all further jobs.
# Since we can do a "master" run (on push and PR to a master branch) and "non-master" run, it generates matrices with different
#  size according to that information.
jobs:
  build-managed-packages:
    name: Build managed package ${{ matrix.name }}
    runs-on: ubuntu-20.04
    strategy:
      matrix:
        packages:
          - { "name": "deb-aio-x86_64" }
          - { "name": "rpm-aio-x86_64" }
          - { "name": "deb-aio-arm64" }
          - { "name": "rpm-aio-arm64" }
          - { "name": "deb-non-aio" }
          - { "name": "rpm-non-aio" }

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@e81a89b1732b9c48d79cd809d8d81d79c4647a18 # v2
        with:
          image: tonistiigi/binfmt:qemu-v6.2.0
          platforms: all

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@f03ac48505955848960e80bbb68046aa35c7b9e7 # v2.0.0
        with:
          driver-opts: network=host

      - name: Prepare environment.
        uses: ./.github/actions/execute-runner
        with:
          runner-fqdn: "agent_build_refactored.__init__.BuildTestEnvironment"

      - name: Prepare SSH
        id: prepare-ssh
        shell: bash
        run: |
          echo '${{ secrets.CT_AWS_DEV_EC2_PRIVATE_KEY }}' > /tmp/private_key.pem
          chmod 600 /tmp/private_key.pem
          eval `ssh-agent -s`

          cat "/tmp/private_key.pem" | ssh-add -
          echo "ssh_auth_sock=${SSH_AUTH_SOCK}" >> $GITHUB_OUTPUT


      - name: Prepare everything that is needed by builder '${{ matrix.name }}'
        uses: ./.github/actions/execute-runner
        env:
          SSH_AUTH_SOCK: ${{ steps.prepare-ssh.outputs.ssh_auth_sock }}
        with:
          runner-fqdn: ${{ matrix.builder-fqdn }}
          aws_access_key: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
          aws_secret_key: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
          aws_private_key_path: "/tmp/private_key.pem"
          aws_private_key_name: ${{ inputs.aws_private_key_name }}
          aws_region: ${{ inputs.aws_region }}
          aws_security_group: ${{ inputs.aws_security_group }}
          aws_security_groups_prefix_list_id: ${{ inputs.aws_prefix_list_id }}
          aws_objects_name_prefix: ${{ inputs.aws_objects_name_prefix }}

      # Before we build needed packages, we check if the target repo already contains dependency
      # 'scalyr-agent-python3' and 'scalyr-agent-libs' packages. If there are such packages, then we reuse them
      # instead of building.
      #
      # First get last version package file names from repository.
      - name: Get last packages names from repo for the '${{ matrix.name }}'
        id: get_last_packages_names
        run: |
            set -e
          
            echo "last_repo_python_package_name=${LAST_REPO_PYTHON_PACKAGE_NAME}" >> $GITHUB_OUTPUT
            echo "last_repo_agent_libs_package_name=${LAST_REPO_AGENT_LIBS_PACKAGE_NAME}" >> $GITHUB_OUTPUT

      # Look for python package in cache, so we don't have to download it every time from the Packagecloud.
      - name: Cache last repo Python package.
        if: steps.get_last_packages_names.outputs.last_repo_python_package_name
        id: cache_python
        uses: actions/cache@v3
        with:
          path: /tmp/python-package
          key: python-package-${{ steps.get_last_packages_names.outputs.last_repo_python_package_name }}-${{ matrix.name }}-v1

      # Look for agent-libs package in cache, so we don't have to download it every time from the Packagecloud.
      - name: Cache last repo agent libs package.
        if: steps.get_last_packages_names.outputs.last_repo_agent_libs_package_name
        id: cache_agent_libs
        uses: actions/cache@v3
        with:
          path: /tmp/agent-libs-package
          key: agent-libs-package-${{ steps.get_last_packages_names.outputs.last_repo_agent_libs_package_name }}-${{ matrix.name }}-v1

      # If python package is not in cache, then we have to download it from the Packagecloud.
      - name: Download or use cached python package
        # if: steps.get_last_packages_names.outputs.last_repo_python_package_name && steps.cache_python.outputs.cache-hit != 'true'
        id: download_python
        run: |
            set -e 
            if [ -n "${{ steps.get_last_packages_names.outputs.last_repo_python_package_name }}" ] && [ "${{ steps.cache_python.outputs.cache-hit }}" != "true" ]; then
              LAST_REPO_PYTHON_PACKAGE_PATH=$(
                python3 build_package_new_refactored.py ${{ matrix.name }} \
                download_package \
                --user-name "${{ secrets.PACKAGE_CLOUD_USER }}" \
                --repo-name "${{ secrets.PACKAGE_CLOUD_INTERNAL_REPO }}" \
                --token ${{ secrets.PACKAGE_CLOUD_TOKEN }} \
                --package-filename "${{ steps.get_last_packages_names.outputs.last_repo_python_package_name }}" \
                --output-dir /tmp/python-package
              )
              echo "::notice::Re-using downloaded python package from the Packagecloud."
            elif [ -n "${{ steps.get_last_packages_names.outputs.last_repo_python_package_name }}" ]; then
              LAST_REPO_PYTHON_PACKAGE_PATH="/tmp/python-package/${{ steps.get_last_packages_names.outputs.last_repo_python_package_name }}"
              echo "::notice::Re-using python package from cache."
            else
              echo "::notice::No python packages to reuse."
            fi
              
            
            echo "last_repo_python_package_path=${LAST_REPO_PYTHON_PACKAGE_PATH}" >> $GITHUB_OUTPUT

      # If agent-lib package is not in cache, then we have to download it from the Packagecloud.
      - name: Download or use cached agent libs package
        #if: steps.get_last_packages_names.outputs.last_repo_agent_libs_package_name && steps.cache_agent_libs.outputs.cache-hit != 'true'
        id: download_agent_libs
        run: |
            set -e
            if [ -n "${{ steps.get_last_packages_names.outputs.last_repo_agent_libs_package_name }}" ] && [ "${{ steps.cache_agent_libs.outputs.cache-hit }}" != "true" ]; then
              LAST_REPO_AGENT_LIBS_PACKAGE_PATH=$(
                python3 build_package_new_refactored.py ${{ matrix.name }} \
                download_package \
                --user-name "${{ secrets.PACKAGE_CLOUD_USER }}" \
                --repo-name "${{ secrets.PACKAGE_CLOUD_INTERNAL_REPO }}" \
                --token ${{ secrets.PACKAGE_CLOUD_TOKEN }} \
                --package-filename "${{ steps.get_last_packages_names.outputs.last_repo_agent_libs_package_name }}" \
                --output-dir /tmp/agent-libs-package
              )
              echo "::notice::Re-using downloaded agent-libs package from the Packagecloud."
            elif [ -n "${{ steps.get_last_packages_names.outputs.last_repo_agent_libs_package_name }}" ]; then
              LAST_REPO_AGENT_LIBS_PACKAGE_PATH="/tmp/agent-libs-package/${{ steps.get_last_packages_names.outputs.last_repo_agent_libs_package_name }}"
              echo "::notice::Re-using agent-libs package from cache."
            else
              echo "::notice::No agent-libs packages to reuse."
            fi
          
            echo "last_repo_agent_libs_package_path=${LAST_REPO_AGENT_LIBS_PACKAGE_PATH}" >> $GITHUB_OUTPUT

      # Finally build the packages. We also specify already pre-downloaded dependency 'python' and 'agent-libs' packages
      # to reuse them instead of building if they are not changed.
      - name: Build managed package with builder '${{ matrix.name }}'
        env:
          SSH_AUTH_SOCK: ${{ steps.prepare-ssh.outputs.ssh_auth_sock }}
          AWS_ACCESS_KEY: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
          AWS_SECRET_KEY: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
          AWS_PRIVATE_KEY_NAME: ${{ inputs.aws_private_key_name }}
          AWS_PRIVATE_KEY_PATH: "/tmp/private_key.pem"
          AWS_REGION: ${{ inputs.aws_region }}
          AWS_SECURITY_GROUP: ${{ inputs.aws_security_group }}
          AWS_SECURITY_GROUPS_PREFIX_LIST_ID: ${{ inputs.aws_prefix_list_id }}
          AWS_OBJECTS_NAME_PREFIX: ${{ inputs.aws_objects_name_prefix }}
        run: |
            python3 build_package_new_refactored.py ${{ matrix.name }} build 

      - name: Save packages as artifact
        uses: actions/upload-artifact@v3
        with:
          name: linux-packages-${{ matrix.name }}
          path: build
          retention-days: 1

  test_managed_packages:
    name: Test package on ${{ matrix.distro-name }}-${{ matrix.remote-machine-type }}, ${{ matrix.name }}
    if: github.ref_type == 'branch' && github.ref_name != '_release_build'
    needs:
      - build-managed-packages

    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        package:
          - { "name": "deb-aio-x86_64", "arch": "x86_64", "distro-name": "ubuntu2204",    "remote-machine-type": "ec2"    }
          - { "name": "deb-aio-x86_64", "arch": "x86_64", "distro-name": "ubuntu2004",    "remote-machine-type": "ec2"    }
          - { "name": "deb-aio-x86_64", "arch": "x86_64", "distro-name": "ubuntu1804",    "remote-machine-type": "ec2"    }
          - { "name": "deb-aio-x86_64", "arch": "x86_64", "distro-name": "ubuntu1604",    "remote-machine-type": "ec2"    }
          - { "name": "deb-aio-x86_64", "arch": "x86_64", "distro-name": "ubuntu1404",    "remote-machine-type": "docker" }
          - { "name": "deb-aio-x86_64", "arch": "x86_64", "distro-name": "debian10",      "remote-machine-type": "ec2"    }
          - { "name": "deb-aio-x86_64", "arch": "x86_64", "distro-name": "debian11",      "remote-machine-type": "docker" }
          - { "name": "rpm-aio-x86_64", "arch": "x86_64", "distro-name": "centos8",       "remote-machine-type": "docker" }
          - { "name": "rpm-aio-x86_64", "arch": "x86_64", "distro-name": "centos7",       "remote-machine-type": "ec2"    }
          - { "name": "rpm-aio-x86_64", "arch": "x86_64", "distro-name": "centos6",       "remote-machine-type": "docker" }
          - { "name": "rpm-aio-x86_64", "arch": "x86_64", "distro-name": "amazonlinux2",  "remote-machine-type": "ec2"    }
          - { "name": "deb-aio-arm64",  "arch": "arm64",  "distro-name": "ubuntu1404",    "remote-machine-type": "docker" }
          - { "name": "rpm-aio-arm64",  "arch": "arm64",  "distro-name": "centos7",       "remote-machine-type": "docker" }
          - { "name": "deb-non-aio",    "arch": "x86_64", "distro-name": "ubuntu1404",    "remote-machine-type": "docker" }
          - { "name": "deb-non-aio",    "arch": "x86_64", "distro-name": "ubuntu2204",    "remote-machine-type": "docker" }
          - { "name": "rpm-non-aio",    "arch": "x86_64", "distro-name": "centos7",       "remote-machine-type": "docker" }
          - { "name": "rpm-non-aio",    "arch": "x86_64", "distro-name": "amazonlinux2",  "remote-machine-type": "docker" }
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@e81a89b1732b9c48d79cd809d8d81d79c4647a18 # v2
        with:
          image: tonistiigi/binfmt:qemu-v6.2.0
          platforms: all

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@f03ac48505955848960e80bbb68046aa35c7b9e7 # v2.0.0
        with:
          driver-opts: network=host


      - name: Prepare environment.
        uses: ./.github/actions/execute-runner
        with:
          runner-fqdn: "agent_build_refactored.__init__.BuildTestEnvironment"

      - name: Download built packages.
        uses: actions/download-artifact@v3
        with:
          name:  linux-packages-${{ matrix.name }}
          path: /tmp/packages

      - name: Prepare everything that is needed by builder '${{ matrix.name }}'
        uses: ./.github/actions/execute-runner
        with:
          runner-fqdn: ${{ matrix.builder-fqdn }}

      - name: Prepare cached steps for package '${{ matrix.name }}' tests
        uses: ./.github/actions/execute-runner
        with:
          runner-fqdn: "tests.end_to_end_tests.run_in_remote_machine.portable_pytest_runner.PortablePytestRunnerBuilder_${{ matrix.arch }}"

      - name: Test '${{ matrix.name }}' packages
        env:
          AWS_ACCESS_KEY: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
          AWS_SECRET_KEY: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
          AWS_PRIVATE_KEY_NAME: ${{ inputs.aws_private_key_name }}
          AWS_PRIVATE_KEY_PATH: "/tmp/private_key.pem"
          AWS_REGION: ${{ inputs.aws_region }}
          AWS_SECURITY_GROUP: ${{ inputs.aws_security_group }}
          AWS_SECURITY_GROUPS_PREFIX_LIST_ID: ${{ inputs.aws_prefix_list_id }}
          AWS_OBJECTS_NAME_PREFIX: ${{ inputs.aws_objects_name_prefix }}
        run: |
          echo "${{ secrets.CT_AWS_DEV_EC2_PRIVATE_KEY }}" > /tmp/private_key.pem
          chmod 600 /tmp/private_key.pem
          
          python3 -m pytest tests/end_to_end_tests/managed_packages_tests \
            -s \
            --builder-name ${{ matrix.name }} \
            --distro-name ${{ matrix.distro-name }} \
            --remote-machine-type ${{ matrix.remote-machine-type }} \
            --packages-source-type dir \
            --packages-source /tmp/packages \
            --scalyr-api-key ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_WRITE }} \
            --scalyr-api-read-key ${{ secrets.CT_SCALYR_TOKEN_PROD_US_CLOUDTECH_TESTING_READ }} \
            --test-session-suffix ${{ github.run_id }}-${{ github.run_number }}-${{ github.run_attempt }}

  clean-ec2-tests-objects:
    name: Remove ec2 test workflow prefix list entries
    if: ${{ always() }}
    needs:
      - test_managed_packages
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install python
        uses: actions/setup-python@v4
        with:
          python-version: "3.8.13"

      - name: Prepare environment.
        uses: ./.github/actions/execute-runner
        with:
          runner-fqdn: "agent_build_refactored.__init__.BuildTestEnvironment"

      - name: Cleanup old prefix lists for ec2 test security group.
        env:
          AWS_ACCESS_KEY: ${{ secrets.CT_AWS_DEV_EC2_ACCESS_KEY }}
          AWS_SECRET_KEY: ${{ secrets.CT_AWS_DEV_EC2_SECRET_KEY }}
          AWS_PRIVATE_KEY_NAME: ${{ inputs.aws_private_key_name }}
          AWS_PRIVATE_KEY_PATH: "/tmp/private_key.pem"
          AWS_REGION: ${{ inputs.aws_region }}
          AWS_SECURITY_GROUP: ${{ inputs.aws_security_group }}
          AWS_SECURITY_GROUPS_PREFIX_LIST_ID: ${{ inputs.aws_prefix_list_id }}
          AWS_OBJECTS_NAME_PREFIX: ${{ inputs.aws_objects_name_prefix }}
        run: |
          python3 agent_build_refactored/tools/run_in_ec2/cleanup_ec2_objects.py
